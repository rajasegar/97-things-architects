<script>
 import Slide from '../lib/Slide.svelte';
</script>

<Slide>
<Slide>
<p><div class="chapter" title="Chapter 37. Software Architecture Has Ethical Consequences"><div class="titlepage"><div><div><h1 class="title"><a id="software_architecture_has_ethical_conseq"/>Chapter 37. Software Architecture Has Ethical Consequences</h1></div></div></div><div class="epigraph"><p>Michael Nygard wrote Release It! Design and Deploy
      Production-Ready Software (Pragmatic Bookshelf), which won a Jolt
      Productivity award in 2008. His other writings can be found at <a class="ulink" href="http://www.michaelnygard.com/blog">http://www.michaelnygard.com/blog</a>.<a class="indexterm" id="IDX-CHP-37-0227"/></p><div class="attribution"><span>—<span class="attribution">Michael Nygard</span></span></div></div><div class="informalfigure"><div class="mediaobject"><a id="I_mediaobject37_d1e2266"/><img alt="image with no caption" src="/images/id2698225/OEBPS/httpatomoreillycomsourceoreillyimages251910.png.jpg"/></div></div><p><span class="strong"><strong>THE ETHICAL DIMENSION IN SOFTWARE</strong></span>
    is obvious when we are talking about civil rights, identity theft, or
    malicious software. But it arises in less exotic circumstances. If
    programs are successful, they affect the lives of thousands or millions of
    people. That impact can be positive or negative. The program can make
    their lives better or worse—even if just in minute proportions.</p><p>Every time I make a decision about how a program behaves, I am
    really deciding what my users can and cannot do, in ways more inflexible
    than law. There is no appeals court for required fields or mandatory
    workflow.</p><p>Another way to think about it is in terms of multipliers. Think back
    to the last major Internet worm, or when a big geek movie came out. No
    doubt, you heard or read a story about how much productivity this thing
    would cost the country. You can always find some analyst with an estimate
    of outrageous damages, blamed on anything that takes people away from
    their desks. The real moral of this story isn't about innumeracy in the
    press, or self-aggrandizing accountants. It's about multipliers, and the
    effect they can have.</p><p>Suppose you have a decision to make about a particular feature. You
    can do it the easy way in about a day, or the hard way in about a week.
    Which way should you do it? Suppose that the easy way makes four new
    fields required, whereas doing it the hard way makes the program smart
    enough to handle incomplete data. Which way should you do it?</p><p>Required fields seem innocuous, but they are always an imposition of
    your will on users. They force users to gather more information before
    starting their jobs. This often means they have to keep their data on
    Post-It notes until they've got everything together at the same time,
    resulting in lost data, delays, and general frustration.</p><p>As an analogy, suppose I'm putting up a sign on my building. Is it
    OK to mount the sign just six feet up on the wall, forcing pedestrians to
    duck or go around it? It's easier for me to hang the sign if I don't need
    a ladder and scaffold, and the sign wouldn't even block the sidewalk. I
    get to save an hour installing the sign, at the expense of taking two
    seconds away from every pedestrian passing my store. Over the long run,
    all of those two-second diversions are going to add up to many, many times
    more than the hour that I saved.</p><p>It's not ethical to worsen the lives of others, even a small bit,
    just to make things easy for yourself. Successful software affects
    millions of people. Every decision you make imposes your will on your
    users. Always be mindful of the impact your decisions have on those
    people. You should be willing to bear large burdens to ease theirs.</p></div></p>
</Slide>
		<Slide>
				<h2>37. Software Architecture Has Ethical Consequences</h2>
		</Slide>
</Slide>
